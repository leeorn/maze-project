{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_OF_MARBLE = 1 # cm\n",
    "PIXEL_TO_CM = 2.54 / 96 # Assuming the pixel density is 96\n",
    "PATH_WIDTH = SIZE_OF_MARBLE // PIXEL_TO_CM\n",
    "\n",
    "PATH_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color a box size of width starting at row indx and column index on the image passed\n",
    "def color_box(img, row_idx, col_idx, width):\n",
    "    for i in range(width):\n",
    "        for j in range(width):\n",
    "#             if(img[i,j,0] > 127 and img[i,j,1] > 127 and img[i,j,2] > 127):\n",
    "            img[i,j,:] = (0, 255, 0)x\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('pic.jpg')\n",
    "img_a = color_box(img, 0, 0, 75)\n",
    "cv2.imshow(\"im\", img_a)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def color_open_space(contour_img, width):\n",
    "#     width = int(width)\n",
    "#     # gets the max value that a col/ row can have (still in the picture)\n",
    "#     max_col_size = contour_img.shape[1]\n",
    "#     max_row_size = contour_img.shape[0]\n",
    "    \n",
    "#     to_color_list = []\n",
    "#     for row in range(max_row_size):\n",
    "#         for col in range(max_col_size):\n",
    "#             if (col + width < max_col_size) & (row + width < max_row_size):\n",
    "#                 to_color_list.append((col, row))\n",
    "#                 # jump to the next block\n",
    "#                 col += width\n",
    "#                 row += width\n",
    "    \n",
    "    \n",
    "#     return to_color_list         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clear(img, row_idx, col_idx, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = color_open_space(img, 75)\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "img = cv2.imread('pic.jpg')\n",
    "\n",
    "# gray scale\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "\n",
    "# find contours\n",
    "contours,hierachy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# draw the contour\n",
    "img_cont = cv2.drawContours(img, contours, 0, (0,255,0), 2)\n",
    "\n",
    "a = color_open_space(img_cont, PATH_WIDTH)\n",
    "\n",
    "cv2.imshow(\"im\", a)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image as grayscale\n",
    "img = cv2.imread('pic3.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# threshold input image using otsu thresholding as mask and refine with morphology\n",
    "ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU) \n",
    "kernel = np.ones((9,9), np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# put thresh into \n",
    "result = img.copy()\n",
    "result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "result[:, :, 3] = mask\n",
    "\n",
    "# save resulting masked image\n",
    "cv2.imwrite('retina_masked.png', result)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Checks the size of the marbel\n",
    "SIZE_OF_MARBLE = 2 # cm\n",
    "PIXEL_TO_CM = 2.54 / 96 # Assuming the pixel density is 96\n",
    "PATH_WIDTH = int(SIZE_OF_MARBLE // PIXEL_TO_CM)\n",
    "\n",
    "PATH_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that checks if a box is blocked to the marble or not. Does it by working on box size of the marble \n",
    "# (PATH_WIDTH by PATH_WIDTH). If any of the pixel within that box is black (value below 127) the box is considered\n",
    "# blocked\n",
    "# Takes in the image to test, the row and column indecies to start the box from and the width of the marble\n",
    "# Returns True if the box is blocked, else True\n",
    "def is_box_blocked(img, row_idx, col_idx, width):\n",
    "    # if the box is block\n",
    "    blocked = False\n",
    "    \n",
    "    # check each idx in that box, if it's not white, the box is block, return true\n",
    "    for r in range(row_idx, row_idx+width):\n",
    "        for c in range(col_idx, col_idx+width):\n",
    "            \n",
    "            if row_idx+width >= img.shape[0] or col_idx+width >= img.shape[1]:\n",
    "                block = True\n",
    "                \n",
    "            elif img[r,c,0] < 175 and img[r,c,1] < 175 and img[r,c,2] < 175:\n",
    "                blocked = True\n",
    "                break\n",
    "        \n",
    "        if blocked:\n",
    "            break\n",
    "            \n",
    "    return blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that colors all the possible areas where the marble can go to.\n",
    "# Takes in the img of the maze, and the width of the marble\n",
    "# returns the colored image\n",
    "def color_path(img, width):\n",
    "    start_idx = False\n",
    "    \n",
    "    for r in range(0, img.shape[0], width):\n",
    "        for c in range(0, img.shape[1], width):\n",
    "\n",
    "            if not is_box_blocked(img, r, c, width):\n",
    "                # save the first indices of the first box (starting point) \n",
    "                if not start_idx:\n",
    "                    first_row = r\n",
    "                    first_col = c\n",
    "                    start_idx = True\n",
    "                    \n",
    "                # end index for the box\n",
    "                row_end = r + width\n",
    "                col_end = c + width\n",
    "                \n",
    "                # if out of bound - continue\n",
    "                if row_end >= img.shape[0] or col_end >= img.shape[1]:\n",
    "                    continue\n",
    "\n",
    "                # color the box green\n",
    "                img[r:row_end, c:col_end] = [0,255,0]\n",
    "    \n",
    "    # color the start point as red\n",
    "    img[first_row:first_row+width, first_col:first_col+width+500] = [0,0,255]\n",
    "    return img, first_col, first_row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image\n",
    "img = cv2.imread('pic.jpg')\n",
    "# call the function to color the image\n",
    "img,c,r = color_path(img, PATH_WIDTH)\n",
    "\n",
    "# print(c,r)\n",
    "\n",
    "# show the new image\n",
    "cv2.imshow(\"Colored-IMG\", img)\n",
    "# wait to close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOT GOOD\n",
    "\n",
    "# import numpy as np\n",
    "# import cv2 as cv\n",
    "# from matplotlib import pyplot as plt\n",
    "# img = cv.imread('messi5.jpg',0)\n",
    "# edges = cv.Canny(img,100,200)\n",
    "# plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "# plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "# plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's load a simple image with 3 black squares \n",
    "image = cv2.imread('new-maze.jpg') \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "# Grayscale \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "# Find Canny edges \n",
    "edged = cv2.Canny(gray, 30, 200) \n",
    "cv2.waitKey(0) \n",
    "  \n",
    "# Finding Contours \n",
    "# Use a copy of the image e.g. edged.copy() \n",
    "# since findContours alters the image \n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "  \n",
    "cv2.imshow('Canny Edges After Contouring', edged) \n",
    "cv2.waitKey(0) \n",
    "# v2.destroyAllWindows()\n",
    "  \n",
    "# print(\"Number of Contours found = \" + str(len(contours))) \n",
    "  \n",
    "# # Draw all contours \n",
    "# # -1 signifies drawing all contours \n",
    "# cv2.drawContours(image, contours, -1, (0, 255, 0), 3) \n",
    "  \n",
    "# cv2.imshow('Contours', image) \n",
    "# cv2.waitKey(0) \n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects the walls, and write the corredinates of them to a list\n",
    "# returns the tuple of where we have the walls\n",
    "def find_contour(img):\n",
    "    # Grayscale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Find Canny edges \n",
    "    edged = cv2.Canny(gray, 30, 200) \n",
    "    \n",
    "    edge_idx = []\n",
    "    for row in range(edged.shape[0]):\n",
    "        for col in range(edged.shape[1]):\n",
    "            if edged[row][col]:\n",
    "                print(row,col)\n",
    "                edge_idx.append((row,col))\n",
    "                \n",
    "    return edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cv2.imread('new-maze.jpg') \n",
    "e = find_contour(a)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the image\n",
    "# img_with_end = cv2.imread('img_masked2.png')\n",
    "\n",
    "\n",
    "# # show the new image\n",
    "# cv2.imshow(\"Colored-IMG\", img_with_end)\n",
    "\n",
    "# # wait to close the window\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, row, col, prev, color):\n",
    "        self.row_idx = row\n",
    "        self.col_idx = col\n",
    "        self.prev = prev\n",
    "        self.color = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import deque\n",
    "\n",
    "# def shortest_path(img, start_row, start_idx, width):\n",
    "#     # inite a queue (FIFO)\n",
    "#     q = deque()\n",
    "#     # create a node object\n",
    "#     node = Node(start_row, start_idx, None, None)\n",
    "#     # append the first node to the queue\n",
    "#     q.append(node)\n",
    "    \n",
    "#     # while the queue is not empty, continue looking for the end\n",
    "#     while q:\n",
    "#         # checks if reach the end (the color is read)\n",
    "#         n = q.popleft()\n",
    "        \n",
    "#         #########################\n",
    "# #         print(n.color, n.row_idx, n.col_idx)\n",
    "#         ########################\n",
    "        \n",
    "#         if np.all(img[n.row_idx][n.col_idx] == [0,0,255]):\n",
    "#             return n\n",
    "        \n",
    "#         # check in jumps of 10th of the size of the box\n",
    "#         jump = int(width // 10)\n",
    "        \n",
    "#         r = n.row_idx + jump\n",
    "#         c = n.col_idx + jump\n",
    "        \n",
    "#         # checks if the next move is valid, if so add node to queue\n",
    "#         if np.all(img[r][c] == [0, 255, 0]):\n",
    "#             q.append(Node(r, c, n, [0,255,0]))\n",
    "            \n",
    "    \n",
    "#     # if reached here - no path was found\n",
    "#     print(\"DIDN'T FIND PATH\")\n",
    "#     return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = cv2.imread('img_masked2.png')\n",
    "n = shortest_path(img_with_end, 50, 50, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_with_end[50][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pic[50][50] \n",
    "if np.all(pic[50][50] == [0,255,0]):\n",
    "    print(\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show the new image\n",
    "# cv2.imshow(\"Colored-IMG\", pic)\n",
    "# # wait to close the window\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detects the walls, and write the corredinates of them to a list\n",
    "# returns the tuple of where we have the walls\n",
    "def find_contour(img):\n",
    "    # Grayscale \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Find Canny edges \n",
    "    edged = cv2.Canny(gray, 30, 200) \n",
    "    \n",
    "    edge_idx = []\n",
    "    for row in range(edged.shape[0]):\n",
    "        for col in range(edged.shape[1]):\n",
    "            if edged[row][col]:\n",
    "                edge_idx.append((row,col))\n",
    "                \n",
    "    return edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_move(img_shape, edges, row_idx, col_idx):\n",
    "    # less than the row # or col #\n",
    "    if row_idx < 0 or col_idx < 0:\n",
    "        return False\n",
    "\n",
    "    # larger than the # of rows OR # of cols (out of bound)\n",
    "    if row_idx >= img_shape[0] or col_idx >= img_shape[1]:\n",
    "        return False\n",
    "    \n",
    "    # if the index is a wall\n",
    "    if (row_idx, col_idx) in edges:\n",
    "        return False\n",
    "    \n",
    "    # it's a valid move\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, row, col, prev, color):\n",
    "        self.row_idx = row\n",
    "        self.col_idx = col\n",
    "        self.prev = prev\n",
    "        self.color = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def shortest_path2(img, edges, start_row, start_idx):\n",
    "    # inite a queue (FIFO)\n",
    "    q = deque()\n",
    "    # create a node object\n",
    "    node = Node(start_row, start_idx, None, None)\n",
    "    # append the first node to the queue\n",
    "    q.append(node)\n",
    "    \n",
    "    \n",
    "    c = 0\n",
    "    \n",
    "    # while the queue is not empty, continue looking for the end\n",
    "    while q:\n",
    "        n = q.popleft()\n",
    "        \n",
    "        # checks if reach the end (the color is read). if so return the node\n",
    "        if n.color == [0,0,255]:\n",
    "            return n\n",
    "        \n",
    "        # check if can move to left, up, right, down\n",
    "        if valid_move(img.shape, edges, n.row_idx, n.col_idx-1): # checks left\n",
    "            q.append(Node(n.row_idx, n.col_idx-1, n, [0,0,0]))\n",
    "            \n",
    "        if valid_move(img.shape, edges, n.row_idx+1, n.col_idx): # checks up\n",
    "            q.append(Node(n.row_idx+1, n.col_idx, n, [0,0,0]))\n",
    "            \n",
    "        if valid_move(img.shape, edges, n.row_idx, n.col_idx +1): # checks right\n",
    "            q.append(Node(n.row_idx, n.col_idx +1, n, [0,0,0]))\n",
    "            \n",
    "        if valid_move(img.shape, edges, n.row_idx-1, n.col_idx): # checks down\n",
    "            q.append(Node(n.row_idx-1, n.col_idx , n, [0,0,0]))\n",
    "            \n",
    "        if c == 100:\n",
    "#             print(c, n.row_idx, n.col_idx)\n",
    "            c = 0\n",
    "    \n",
    "        c += 1\n",
    "    # if reached here - no path was found\n",
    "    print(\"DIDN'T FIND PATH\")\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, per):\n",
    "\n",
    "    scale_percent = per # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    \n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 288, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2a9a0eeb52eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# find shortest path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mshortest_path2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-68647eacbc7a>\u001b[0m in \u001b[0;36mshortest_path2\u001b[1;34m(img, edges, start_row, start_idx)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalid_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# checks down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_idx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol_idx\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# algo\n",
    "# load image\n",
    "pic = cv2.imread('new-maze-masked.jpg')\n",
    "print(img_resized.shape)\n",
    "\n",
    "# resize img\n",
    "img_resized = resize(pic, 30)\n",
    "\n",
    "# get edges\n",
    "edge_list = find_contour(img_resized)\n",
    "\n",
    "# find shortest path\n",
    "shortest_path2(img_resized, edge_list, 10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
